{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "87tUDV9yPkbT"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#Import the necessary methods from tweepy library\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "import json\n",
    "\n",
    "#Variables that contains the user credentials to access Twitter API\n",
    "access_token = \"\"\n",
    "access_token_secret = \"\"\n",
    "consumer_key = \"\"\n",
    "consumer_secret = \"\"\n",
    "\n",
    "# # # # TWITTER STREAMER # # # #\n",
    "class TwitterStreamer():\n",
    "    \"\"\"\n",
    "    Class for streaming and processing live tweets.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def stream_tweets(self, fetched_tweets_filename, hash_tag_list):\n",
    "        # This handles Twitter authetification and the connection to Twitter Streaming API\n",
    "        listener = StdOutListener(fetched_tweets_filename)\n",
    "        auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "        stream = Stream(auth, listener)\n",
    "\n",
    "        # This line filter Twitter Streams to capture data by the keywords:\n",
    "        stream.filter(languages=[\"en\"], track=hash_tag_list)\n",
    "\n",
    "\n",
    "# # # # TWITTER STREAM LISTENER # # # #\n",
    "class StdOutListener(StreamListener):\n",
    "    \"\"\"\n",
    "    This is a basic listener that just prints received tweets to stdout.\n",
    "    \"\"\"\n",
    "    count=0\n",
    "\n",
    "    def __init__(self, fetched_tweets_filename):\n",
    "        self.fetched_tweets_filename = fetched_tweets_filename\n",
    "\n",
    "    def on_data(self, data):\n",
    "        try:\n",
    "            # print(data)\n",
    "            with open(self.fetched_tweets_filename, 'a', newline='') as tf:\n",
    "                tweet = json.dumps(data, ensure_ascii=False)\n",
    "                tf.write(data)\n",
    "                if (self.count%100==0):print(self.count)\n",
    "                self.count=self.count+1\n",
    "\n",
    "            #\t\ttweet = json.loads(data)\n",
    "            #      \t    with open('your_data.json', 'a') as my_file:\n",
    "            #                json.dump(tweet, my_file)\n",
    "            return True\n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data %s\" % str(e))\n",
    "        return True\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(\"error \"+str(status))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Authenticate using config.py and connect to Twitter Streaming API.\n",
    "    hash_tag_list = ['stockmarket', 'bitcoin', 'money', 'trading', 'forextrader', 'investment', 'wallstreet', 'stocks', 'entrepreneur', 'forex', 'trader', 'investor', 'investing', 'cryptocurrency', 'invest', 'business', 'daytrader', 'binaryoptions', 'forexsignals', 'profit', 'success', 'finance', 'wealth', 'makemoneyonline', 'forexlifestyle', 'forextrading', 'motivation', 'millionaire', 'entrepreneurship', 'daytrading']\n",
    "    fetched_tweets_filename = \"tweets7.json\"\n",
    "\n",
    "    twitter_streamer = TwitterStreamer()\n",
    "    twitter_streamer.stream_tweets(fetched_tweets_filename, hash_tag_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5703,
     "status": "ok",
     "timestamp": 1588350201433,
     "user": {
      "displayName": "Raspberry Pi",
      "photoUrl": "",
      "userId": "09371942930627630010"
     },
     "user_tz": 300
    },
    "id": "4wYWrE0W3u11",
    "outputId": "fc10aad5-d554-48cc-dc8a-2a1ae9329203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GetOldTweets3\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/f4/a00c2a7c90801abc875325bb5416ce9090ac86d06a00cc887131bd73ba45/GetOldTweets3-0.0.11-py3-none-any.whl\n",
      "Collecting lxml>=3.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/ba/a0e6866057fc0bbd17192925c1d63a3b85cf522965de9bc02364d08e5b84/lxml-4.5.0-cp36-cp36m-manylinux1_x86_64.whl (5.8MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8MB 3.9MB/s \n",
      "\u001b[?25hCollecting pyquery>=1.2.10\n",
      "  Downloading https://files.pythonhosted.org/packages/78/43/95d42e386c61cb639d1a0b94f0c0b9f0b7d6b981ad3c043a836c8b5bc68b/pyquery-1.4.1-py2.py3-none-any.whl\n",
      "Collecting cssselect>0.7.9\n",
      "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
      "Installing collected packages: lxml, cssselect, pyquery, GetOldTweets3\n",
      "  Found existing installation: lxml 4.2.6\n",
      "    Uninstalling lxml-4.2.6:\n",
      "      Successfully uninstalled lxml-4.2.6\n",
      "Successfully installed GetOldTweets3-0.0.11 cssselect-1.1.0 lxml-4.5.0 pyquery-1.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --force-reinstall GetOldTweets3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1588360082898,
     "user": {
      "displayName": "Raspberry Pi",
      "photoUrl": "",
      "userId": "09371942930627630010"
     },
     "user_tz": 300
    },
    "id": "kPlat-RG0YYU",
    "outputId": "509818ec-44df-4b34-fddb-6c08021e1923"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import GetOldTweets3 as got\n",
    "from datetime import*\n",
    "import json,time\n",
    "from bson import json_util\n",
    "\n",
    "def save_30_day_json(tweets,search_keyword):\n",
    "  a = [json.loads(json.dumps(tweets[i].__dict__,  default=json_util.default)) for i in range(len(tweets))]\n",
    "  with open(search_keyword+'.json', 'a') as outfile:\n",
    "      json.dump(a, outfile)\n",
    "  print ('saved successfully in ',search_keyword+'.json','file....')\n",
    "\n",
    "def get_tweets(start_date,search_keyword,debug=False):\n",
    "  q = start_date.split('-')\n",
    "  a = datetime(int(q[0]),int(q[1]),int(q[2]))\n",
    "  a+=timedelta(days=1)\n",
    "  end_date = (a.strftime('%Y-%m-%d'))\n",
    "  tweetCriteria = got.manager.TweetCriteria().setQuerySearch(search_keyword)\\\n",
    "                                            .setLang('en')\\\n",
    "                                            .setSince(start_date)\\\n",
    "                                            .setUntil(end_date)\\\n",
    "                                            .setMaxTweets(3000)\n",
    "                                            # .setTopTweets(True)\\\n",
    "  tweet_batch = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "  if debug: print(start_date,search_keyword,len(tweet_batch))\n",
    "  return tweet_batch\n",
    "\n",
    "def get_30days_tweets(start_date,search_keyword,debug=False):\n",
    "  tweets = []\n",
    "  for i in range(30):\n",
    "    tweet_batch = get_tweets(start_date,search_keyword,debug)\n",
    "    tweets.extend(tweet_batch)\n",
    "    q = start_date.split('-')\n",
    "    a = datetime(int(q[0]),int(q[1]),int(q[2]))\n",
    "    a+=timedelta(days=1)\n",
    "    start_date = (a.strftime('%Y-%m-%d'))\n",
    "    open('start_date','w').write(start_date)\n",
    "    save_30_day_json(tweet_batch,search_keyword)\n",
    "    # time.sleep(30)\n",
    "    # if debug: print (len(tweets),start_date,search_keyword)\n",
    "  return tweets\n",
    "\n",
    "\n",
    "\n",
    "open('start_date','w').write('2017-10-01')\n",
    "open('company_list','w').write(\"AMZN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "46qEjZYvqPBg"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "while(1):\n",
    "  temp = open('company_list','r').read()\n",
    "  keyword_list=list(temp.split('-'))\n",
    "  loop_keyword_list = list(keyword_list)\n",
    "\n",
    "  start_date =open('start_date','r').read()\n",
    "  try:\n",
    "    for search_keyword in loop_keyword_list:\n",
    "      print ('Running for ', search_keyword.upper())\n",
    "      tweets = get_30days_tweets(start_date,search_keyword,debug=True)\n",
    "      print ('Tweets downloaded..')\n",
    "      keyword_list.remove(search_keyword)\n",
    "      open('company_list','w').write('-'.join(keyword_list))\n",
    "\n",
    "      \n",
    "  except Exception as e:\n",
    "    print (e)\n",
    "    open('start_date','w').write(start_date)\n",
    "    open('company_list','w').write('-'.join(keyword_list))\n",
    "    print ('error occoured on: ')\n",
    "    print (start_date,search_keyword)\n",
    "    time.sleep(30)#sleeping for too many request error\n",
    "    print ('continuing')\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 361,
     "status": "ok",
     "timestamp": 1588298669455,
     "user": {
      "displayName": "Raspberry Pi",
      "photoUrl": "",
      "userId": "09371942930627630010"
     },
     "user_tz": 300
    },
    "id": "4zJErAHj0VjH",
    "outputId": "d67c017f-6514-48f7-abd7-7d6d7c85a026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-01 ['AAPL', 'TSLA', 'GOOGL', 'AMZN']\n"
     ]
    }
   ],
   "source": [
    "temp = open('company_list','r').read()\n",
    "keyword_list=list(temp.split('-'))\n",
    "loop_keyword_list = list(keyword_list)\n",
    "\n",
    "start_date =open('start_date','r').read()\n",
    "print (start_date,loop_keyword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MVGQWO76VZow"
   },
   "outputs": [],
   "source": [
    "with open('data.json','r') as out:\n",
    "  red = json.load(out)\n",
    "\n",
    "print ((red[0].keys()))\n",
    "# print ((red[0]['formatted_date']))\n",
    "# p= datetime.datetime.fromtimestamp(1577918767)\n",
    "# print (p.strftime('%B/%Y/%d/ %H-%M-%S'))\n",
    "\n",
    "for i in red:\n",
    "  if i['id'] == red[0]['id']:\n",
    "    print (i['text'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOCQqMGFuG+jqPvkUkaaxHo",
   "collapsed_sections": [],
   "name": "tweet download by date and keyword.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
